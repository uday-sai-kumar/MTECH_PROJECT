import pandas as pd
from malware_set import MalwareSet as ms
import os
from create_data_frame import CreateDataFrame as cdf
from read_file import ReadFile as rf
import feature_selection
from sklearn.model_selection import train_test_split
import train_data
import time
from DataVisualization import pca_visualization
from EnsembleTechniques import ensemble
import pyarrow.feather as feather
feature_map = {
    "activity": {},
    "permission": {},
    "receiver": {},
    "service": {},
    "provider": {},
    "intent_filter": {},
    "api_connection": {},
    "api_content": {},
    "api_file": {},
    "api_intent": {},
    "api_data": {}
}
# feature_map = {
#     "feature": {},
#     "permission": {},
#     "activity": {},
#     "service_receiver": {},
#     "provider": {},
#     "service": {},
#     "intent": {},
#     "api_call": {},
#     "real_permission": {},
#     "call": {},
#     "url": {}
# }
my_path = "/Users/udaysaikumar/Desktop/benignmalwarefiles/"
#files = ["Benign_2015", "Benign_2016", "Benign_2017", "a_1", "a_2", "a_3"]
files = ["Benign_2015", "Benign_2016", "Benign_2017"]
#files = ["Benign_2017"]

file_path = None
def _start() :

   # file_path = '/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/
    #file_path = '/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feature_vectors'



    # all_files = all_files+os.listdir(my_path+files[1])
    # all_files = all_files + os.listdir(my_path + files[2])

    #print(len(all_files))
    data_set = []


    begin = time.time()
    _set = ms.read_malware_files()
    dependent_column = []
    count = 0
    my_files = []
    for file_name in files:
        all_files = os.listdir(my_path + file_name)
        try:
            all_files.remove('.DS_Store')
        except Exception as e:
            None
        for _file in all_files:
            #try:
            rf.read_file(my_path+file_name + '/' + _file, _file, feature_map)
            dependent_column.append(int(0))
            my_files.append(_file)
            # except Exception as e:
            #     my_files.remove(_file)

    malware_path = "/Users/udaysaikumar/Desktop/benignmalwarefiles/Malware_2018_5K"
    malware_file = os.listdir(malware_path)
    malware_file = malware_file
    try:
        malware_file.remove('.DS_Store')
    except Exception as e:
        None

    for _file in malware_file:
        rf.read_file(malware_path + '/' + _file, _file, feature_map)
        dependent_column.append(int(1))
        my_files.append(_file)
    #for _file in all_files:

       # _file_content = rf.read_file(file_path+'/'+_file, _file, feature_map)
       #  try:
       #      if count > 500:
       #          if _file in _set:
       #              rf.read_file(file_path + '/' + _file, _file, feature_map)
       #              dependent_column.append(int(1))
       #              my_files.append(_file)
       #              if (len(dependent_column) > 1000):
       #                  break
       #      else:
       #          rf.read_file(file_path + '/' + _file, _file, feature_map)
       #          if _file in _set:
       #              dependent_column.append(int(1))
       #          else:
       #              count = count + 1
       #              dependent_column.append(int(0))
       #          my_files.append(_file)
       #
       #  except Exception as e:
       #      #print(_file)
       #      #print(_file)
       #      #print('exception -- ', e)
       #      all_files.remove(_file)
    my_keys = []
    for key in feature_map:
        data_map = feature_map[key]
        my_keys = [*my_keys, *data_map.keys()]
    #print('len', len(my_keys))
    #my_keys.append('m_or_b')
    my_data_frame = pd.DataFrame(columns=my_keys, index=my_files)

    my_data_frame.fillna(int(0), inplace=True)    #print(my_data_frame.shape)
    #print(my_data_frame.columns)
    print(my_data_frame.shape)

    # for col in my_data_frame.columns:
    #     my_data_frame[col].values[:] = 0
    #print(my_data_frame.head())
    print('here')
    for key in feature_map:
        data_map = feature_map[key]
        for _key in data_map:
            file_list = data_map[_key]
            for _files in file_list:
                #print(_files)
                my_data_frame.loc[_files, _key] = int(1)
                #print('value is ', my_data_frame.loc[_key, _files])
    print(my_data_frame.shape)
    print('end')
    # print(my_data_frame)
    y = pd.DataFrame(dependent_column, columns=['b_or_m'], index=my_files)
    #y = cdf.create_data_frame(dependent_column)
    print('1 frame', y.shape)
    data_frame = pd.concat([my_data_frame, y], axis=1)
    #feather.write_feather(data_frame, '/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feather_file/my_file')
    #print(_dataframe.loc[0,5])
    #print(_dataframe.iloc[0,:])
    #_data_frame = data_frame.transpose()
    #data_frame.to_csv('/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feature_vectors_drebin.csv', index=False, header=True)
    #print(data_frame.head())
    #print(data_frame.shape)

    #data_frame.drop_duplicates()


    data_frame = data_frame.loc[:, ~data_frame.columns.duplicated()].copy()
    with open('/Users/udaysaikumar/Desktop/FILES/datasets_temp_2.ftr', 'wb') as f:
       feather.write_feather(data_frame, f)


    end = time.time()
    print("Total time taken for loading the data with CSV is -- ", begin-end, ' sec')
    #return data_frame


def _feature_selection():
    a = ['f' + str(i) for i in range(1, 9)]
    _data = pd.read_csv('_feature_vectors.csv')
    print("Select K Best:")
    feature_selection.select_k_best(_data)
    print("Extra Tree Classifier:")
    feature_selection.extree_tree_classifier(_data)
    print("Recursive Feature Elimination:")
    feature_selection.recursive_feature_elimination(_data)
    print("Select From Model:")
    feature_selection.select_from_model(_data)

    ##########################
def columns():
    #_data = pd.read_csv('/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feature_vectors_1.csv')
    _data = pd.read_csv('/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feature_vectors_drebin_1.csv')
    print(_data.shape)
    _list=_data[:-1]
    #print(_list)
    print(_data[_data.columns[:-1]])
    print(_data['b_or_m'])
    #print(_data.columns)
def __start(_data):
    #a = ['f' + str(i) for i in range(1, 9)]
    #_data = pd.read_csv('/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feature_vectors_1.csv')
    #_data = pd.read_csv('/Users/udaysaikumar/Documents/THESIS/CODES/DATASET/feature_vectors_drebin_1.csv')
    # print("Select K Best")
    # feature_selection.select_k_best(_data)
    # print("Extra Tree Classifier")
    # feature_selection.extree_tree_classifier(_data)
    # print("Recursive Feature Elimination")
    # feature_selection.recursive_feature_elimination(_data)
    # print("Select From Model")
    # feature_selection.select_from_model(_data)

    ##########################

    X_train, X_test, y_train, y_test = train_test_split(_data[_data.columns[:-1]], _data['b_or_m'], test_size=0.40, random_state=42)
    print("FULL DATASET")
    start_of_time = time.time()
    train_data.linear_SVC(X_train, X_test, y_train, y_test)

    end_of_time = time.time()
    print("time taken is ", (end_of_time - start_of_time), ' sec')



    # print("####################################") taking a lot of time
    # start_of_time = time.time()
    # train_data.SVC_model(X_train, X_test, y_train, y_test)
    #
    # end_of_time = time.time()
    # print("time taken is ", (end_of_time - start_of_time), ' sec')

    print("####################################")
    start_of_time = time.time()
    train_data.GaussianNB_model(X_train, X_test, y_train, y_test)

    end_of_time = time.time()
    print("time taken is ", (end_of_time - start_of_time), ' sec')

    print("####################################")

    start_of_time = time.time()
    train_data.decison_tree(X_train, X_test, y_train, y_test)

    end_of_time = time.time()
    print("time taken is ", (end_of_time-start_of_time),' sec')

    print("####################################")

def __start_group():
    a = ['f' + str(i) for i in range(1, 9)]
    for i in range(1, 7):
        _data = pd.read_csv('_feature_vectors_'+str(i)+'.csv')
        print("DATASET - "+str(i))
        X_train, X_test, y_train, y_test = train_test_split(_data[a], _data['m_or_b'], test_size=0.40, random_state=42)

        start_of_time = time.time()
        train_data.linear_SVC(X_train, X_test, y_train, y_test)

        end_of_time = time.time()
        print("time taken is ", (end_of_time - start_of_time), ' sec')

        print("####################################")
        start_of_time = time.time()
        train_data.SVC_model(X_train, X_test, y_train, y_test)

        end_of_time = time.time()
        print("time taken is ", (end_of_time - start_of_time), ' sec')

        print("####################################")
        start_of_time = time.time()
        train_data.GaussianNB_model(X_train, X_test, y_train, y_test)

        end_of_time = time.time()
        print("time taken is ", (end_of_time - start_of_time), ' sec')

        print("####################################")

        start_of_time = time.time()
        train_data.decison_tree(X_train, X_test, y_train, y_test)

        end_of_time = time.time()
        print("time taken is ", (end_of_time - start_of_time), ' sec')

        print("####################################")


    # print("Select K Best")
    # feature_selection.select_k_best(_data)
    # print("Extra Tree Classifier")
    # feature_selection.extree_tree_classifier(_data)
    # print("Recursive Feature Elimination")
    # feature_selection.recursive_feature_elimination(_data)
    # print("Select From Model")
    # feature_selection.select_from_model(_data)

    ##########################

    #train_data.linear_SVC(X_train, X_test, y_train, y_test)
    #train_data.SVC_model(X_train, X_test, y_train, y_test)
    #train_data.GaussianNB_model(X_train, X_test, y_train, y_test)

    # start_of_time = time.time()
    # train_data.decison_tree(X_train, X_test, y_train, y_test)
    #
    # end_of_time = time.time()
    # print("time taken is ", (end_of_time-start_of_time),' sec')


def _save_data(_data,_data_one, i):
    _data = pd.concat([_data, _data_one], axis=0)
    _data.to_csv('_feature_vectors_'+str(i)+'.csv', index=False)


def _split_data():
    df = pd.read_csv('_feature_vectors.csv')
    _group = df.groupby('m_or_b')
    group_zero = _group.get_group(0)
    group_one = _group.get_group(1)
    _group_1 = group_zero[:20000:]
    _group_2 = group_zero[20000:40000:]
    _group_3 = group_zero[40000:60000:]
    _group_4 = group_zero[60000:80000:]
    _group_5 = group_zero[80000:100000:]
    _group_6 = group_zero[100000::]
    _save_data(_group_1, group_one, 1)
    _save_data(_group_2, group_one, 2)
    _save_data(_group_3, group_one, 3)
    _save_data(_group_4, group_one, 4)
    _save_data(_group_5, group_one, 5)
    _save_data(_group_6, group_one, 6)
    #
    # _group_1.to_csv('_feature_vectors_1.csv', index=False)
    # _group_2.to_csv('_feature_vectors_2.csv', index=False)
    # _group_3.to_csv('_feature_vectors_3.csv', index=False)
    # _group_4.to_csv('_feature_vectors_4.csv', index=False)
    # _group_5.to_csv('_feature_vectors_5.csv', index=False)
    # _group_6.to_csv('_feature_vectors_6.csv', index=False)
    # for name, group in _group:
    #     print(name)
    #     print(group)
    #     print()


# _start()
_data = None
with open('/Users/udaysaikumar/Desktop/FILES/datasets_3.ftr', 'rb') as f:
    _data = feather.read_feather(f)

# print("Total time taken for loading the data with feather is -- ", begin-end, ' sec')
print(_data.shape)
#pca_visualization.pca_vis(_data)
# begin = time.time()
# print("XGBoost")
# ensemble.xg_boost(_data)
# end = time.time()
#
# print("#####################")
# _begin = time.time()
# print("SVM")
# ensemble.ensemble_technique(_data)
# _end = time.time()
#
#
# print("Total computational time taken with XGBoost -- ", end-begin, ' sec')
# print("Total computational time taken with SVM -- ", _end-_begin, ' sec')
#

#_feature_selection()
#columns()
#__start(_data)

#_split_data()

#__start_group()

